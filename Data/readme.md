This folder contains following datasets, used in the empirical evaluation of Clone-Advisor approach:

<ol>
  <li>inputSequence.txt contains contexts used in the prediction of clone methods with DeepClone model.</li>
  <li>groundTruthClones.txt contains ground truth in terms of clone methods.</li>
  <li>predictedClones.txt contains predicted clone methods generated by DeepClone model. This output (predicted clone method) has been generated with <a href="https://github.com/huggingface/transformers/tree/master/examples/pytorch/text-generation">text generation</a> script of HuggingFace Transformers Library. Finally, it contains dataset and results generated in empirical evaluation of methodology.</li>
  <li>clonecorpus.txt contains list of pre-processed clone methods, used for searching.</li>
  <li>functionalityIds.txt contains functionality Ids belonging to each clone method exists in clonecorpus.txt</li>
  <li>method_annotation.txt contains manual annotatation of inputSequence.txt file, in which '1' represents clone method name exists, while '0' represents clone method name doesnot exist.</li>
  <li>benchmarkmethods.txt contains ground truth of clone methods belonging to benchmark code samples</li>
  <li>functionalityIds_bm.txt  contains functionality Ids belonging to each clone method exists in benchmarkmethods.txt</li>
  <li>inputSequence_bm.txt contains contexts taken from benchmark code samples. These samples are used in the prediction of clone methods with DeepClone model.</li>
  <li>generatedClones_bm.txt contains predicted clone methods generated by DeepClone model from benchmark input sequences (inputSequence_bm.txt). This output (predicted clone method) has been generated with <a href="https://github.com/huggingface/transformers/tree/master/examples/pytorch/text-generation">text generation</a> script of HuggingFace Transformers Library. Finally, it contains dataset and results generated in empirical evaluation of methodology.</li>
</ol>
